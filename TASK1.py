# -*- coding: utf-8 -*-
"""fakenewsdetection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1lXV1hvezUt_Uhxr1wcPMstbpWRhEW_G5
"""

import pandas as pd
import numpy as np
import re
import seaborn as sns
import matplotlib.pyplot as plt
import nltk
from nltk.corpus import stopwords
from wordcloud import WordCloud
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc

nltk.download('stopwords')
stop_words = set(stopwords.words('english'))
fake_df = pd.read_csv("/content/Fake.csv")
real_df = pd.read_csv("/content/True.csv")

fake_df["label"] = 1
real_df["label"] = 0

df = pd.concat([fake_df[["text", "label"]], real_df[["text", "label"]]], axis=0).sample(frac=1, random_state=42).reset_index(drop=True)

print("Dataset Loaded Successfully!")
def clean_text(text):
    text = re.sub(r'\W', ' ', str(text))
    text = text.lower()
    text = re.sub(r'\s+', ' ', text)
    text = ' '.join([word for word in text.split() if word not in stop_words])
    return text

df['text'] = df['text'].apply(clean_text)
print("Text Cleaning Completed!")
X_train, X_test, y_train, y_test = train_test_split(df['text'], df['label'], test_size=0.2, stratify=df['label'], random_state=42)

vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))
X_train_tfidf = vectorizer.fit_transform(X_train)
X_test_tfidf = vectorizer.transform(X_test)

print("Data Split and Vectorized Successfully!")

model = MultinomialNB()
model.fit(X_train_tfidf, y_train)

y_pred = model.predict(X_test_tfidf)
y_prob = model.predict_proba(X_test_tfidf)[:, 1]

print("\n Model Trained Successfully!")
print("\n Classification Report:\n", classification_report(y_test, y_pred))
accuracy = accuracy_score(y_test, y_pred)
print("\n Model Accuracy:", accuracy)

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=['Real', 'Fake'], yticklabels=['Real', 'Fake'])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

feature_names = np.array(vectorizer.get_feature_names_out())
feature_prob = model.feature_log_prob_[1]
top_20_fake_idx = np.argsort(feature_prob)[-20:]

plt.figure(figsize=(10, 5))
plt.barh(feature_names[top_20_fake_idx], feature_prob[top_20_fake_idx], color="red")
plt.xlabel("Importance")
plt.ylabel("Top Words in Fake News")
plt.title("Top 20 Fake News Indicators")
plt.show()

fpr, tpr, _ = roc_curve(y_test, y_prob)
roc_auc = auc(fpr, tpr)

plt.figure(figsize=(6,4))
plt.plot(fpr, tpr, color="blue", lw=2, label="ROC curve (area = {:.2f})".format(roc_auc))
plt.plot([0, 1], [0, 1], color="gray", linestyle="--")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("Receiver Operating Characteristic (ROC) Curve")
plt.legend(loc="lower right")
plt.show()

def predict_news(text):
    cleaned_text = clean_text(text)
    vectorized_text = vectorizer.transform([cleaned_text])
    prediction = model.predict(vectorized_text)
    return "Fake News" if prediction[0] == 1 else "Real News"
test_texts = [
    "New York governor questions the constitutionality of federal tax overhaul",
    "Trump wants Postal Service to charge 'much more' for Amazon shipments",
    "Virginia officials postpone lottery drawing to decide tied statehouse election",
    "Man says he delivered manure to Mnuchin to protest new U.S. tax law",
    "As Trump targets immigrants, U.S. farm sector looks to automate",

    "Bad News For Trump â€” Mitch McConnell Says No To Repealing Obamacare In 2018",
    "Sean Hannity Gets Wrecked For Yelling At Time Magazine For Calling Out Trumpâ€™s Lie",
    "Heiress To Disney Empire Knows GOP Scammed Us â€“ SHREDS Them For Tax Bill",
    "The Internet Brutally Mocks Disneyâ€™s New Trump Robot At Hall Of Presidents",
    "Time Magazine Humiliates Trump After He Lies About Award"
]

for text,i in enumerate (test_texts, start=1):
    print(f"\n Example {text}: {i}")
    print(" Prediction:", predict_news(i))
